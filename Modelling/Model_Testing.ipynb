{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/kaczm/Desktop/Credit Card Risk/default_of_credit_card_clients.csv')\n",
    "target_variable = pd.read_csv('C:/Users/kaczm/Desktop/Credit Card Risk/default_of_credit_card_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join target variable to the dataset\n",
    "\n",
    "df['target'] = target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    23364\n",
       "1     6636\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()\n",
    "\n",
    "# Since the target variable is very imbalanced, we will use SMOTE to balance it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(df):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_smote, X_test, y_smote, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will build several models to see which one performs the best\n",
    "\n",
    "def build_models(X_smote, X_test, y_smote, y_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "    models = [RandomForestClassifier(random_state=42), LogisticRegression(random_state=42), xgb.XGBClassifier(random_state=42)]\n",
    "\n",
    "    best_model_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for model in models:\n",
    "        model.fit(X_smote, y_smote)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        average_score = (accuracy + auc) / 2\n",
    "        \n",
    "        print(model)\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('AUC:', auc)\n",
    "        print('Average Score (Accuracy + AUC) / 2:', average_score)\n",
    "        print('Recall:', recall_score(y_test, y_pred))\n",
    "        print('Precision:', precision_score(y_test, y_pred))\n",
    "        print('F1:', f1_score(y_test, y_pred))\n",
    "\n",
    "        if average_score > best_model_score:\n",
    "            best_model_score = average_score\n",
    "            best_model = model\n",
    "\n",
    "    print('Best model based on average score (Accuracy + AUC) / 2:', best_model)\n",
    "    print('Best model average score:', best_model_score)\n",
    "    return best_model\n",
    "\n",
    "# Example usage:\n",
    "# best_model = build_models(X_smote, X_test, y_smote, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n",
      "Accuracy: 0.7935\n",
      "AUC: 0.7541261166867702\n",
      "Average Score (Accuracy + AUC) / 2: 0.7738130583433851\n",
      "Recall: 0.48743335872048743\n",
      "Precision: 0.5306799336650083\n",
      "F1: 0.5081381500595474\n",
      "LogisticRegression(random_state=42)\n",
      "Accuracy: 0.7311666666666666\n",
      "AUC: 0.7437070109006599\n",
      "Average Score (Accuracy + AUC) / 2: 0.7374368387836633\n",
      "Recall: 0.6260472201066261\n",
      "Precision: 0.4228395061728395\n",
      "F1: 0.5047589806570464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaczm\\.virtualenvs\\Credit_Card_Risk-I-g6zMjZ\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "Accuracy: 0.7955\n",
      "AUC: 0.7565485126740505\n",
      "Average Score (Accuracy + AUC) / 2: 0.7760242563370252\n",
      "Recall: 0.43716679360243715\n",
      "Precision: 0.5404896421845574\n",
      "F1: 0.48336842105263156\n",
      "Best model based on average score (Accuracy + AUC) / 2: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "Best model average score: 0.7760242563370252\n"
     ]
    }
   ],
   "source": [
    "# Now balance data and run the models\n",
    "\n",
    "X_smote, X_test, y_smote, y_test = balance_data(df)\n",
    "\n",
    "best_model_smote= build_models(X_smote, X_test, y_smote, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Feature        Score\n",
      "26         Total_Delays  2298.174644\n",
      "23  Payment_Consistency   340.269930\n",
      "30       Cluster_kmeans   218.829117\n",
      "5                    X6   201.517549\n",
      "6                    X7   160.027300\n",
      "7                    X8   129.692706\n",
      "28     On_Time_Payments   116.272446\n",
      "8                    X9   108.131709\n",
      "9                   X10    92.598810\n",
      "27  Total_Payments_Done    82.647000\n"
     ]
    }
   ],
   "source": [
    "# So the best model with SMOTE was XGBOOST at 0.7760242563370252 average\n",
    "\n",
    "# however, we still need to build models using under and over sampling as well as feature selection so first define a feature selection function\n",
    "\n",
    "def feature_selection_chi_test(df):\n",
    "\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    # Ensure all feature values are non-negative\n",
    "    X = X + abs(X.min())  # Shift values to be non-negative\n",
    "\n",
    "    # Optionally, apply MinMax scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Select the k best features using SelectKBest\n",
    "    best_features = SelectKBest(score_func=chi2, k=10)\n",
    "    fit = best_features.fit(X_scaled, y)\n",
    "    df_scores = pd.DataFrame(fit.scores_)\n",
    "    df_columns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    feature_scores = pd.concat([df_columns, df_scores], axis=1)\n",
    "    feature_scores.columns = ['Feature', 'Score']\n",
    "    print(feature_scores.nlargest(10, 'Score'))\n",
    "\n",
    "    return X[feature_scores.nlargest(10, 'Score')['Feature'].values]\n",
    "\n",
    "\n",
    "# Now balance data and run the models\n",
    "\n",
    "X_selected = feature_selection_chi_test(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaczm\\AppData\\Local\\Temp\\ipykernel_28616\\865991570.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_chi_under['target'] = target_variable\n"
     ]
    }
   ],
   "source": [
    "# now define a function to balance data using under sampling\n",
    "\n",
    "def under_sample(df):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_rus, X_test, y_rus, y_test\n",
    "\n",
    "# Now choose only columns from df based on the selected features, balance and data and run models\n",
    "\n",
    "df_chi_under = df[X_selected.columns] \n",
    "# add target column to the df\n",
    "df_chi_under['target'] = target_variable\n",
    "X_rus, X_test, y_rus, y_test = under_sample(df_chi_under)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n",
      "Accuracy: 0.746\n",
      "AUC: 0.7359002578960034\n",
      "Average Score (Accuracy + AUC) / 2: 0.7409501289480017\n",
      "Recall: 0.6054836252856055\n",
      "Precision: 0.4414214325374792\n",
      "F1: 0.5105973025048169\n",
      "LogisticRegression(random_state=42)\n",
      "Accuracy: 0.755\n",
      "AUC: 0.7403323122681703\n",
      "Average Score (Accuracy + AUC) / 2: 0.7476661561340852\n",
      "Recall: 0.6039603960396039\n",
      "Precision: 0.4549627079747562\n",
      "F1: 0.518979057591623\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "Accuracy: 0.7626666666666667\n",
      "AUC: 0.7444868249769948\n",
      "Average Score (Accuracy + AUC) / 2: 0.7535767458218308\n",
      "Recall: 0.5833968012185834\n",
      "Precision: 0.4662203286670724\n",
      "F1: 0.5182679296346414\n",
      "Best model based on average score (Accuracy + AUC) / 2: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "Best model average score: 0.7535767458218308\n"
     ]
    }
   ],
   "source": [
    "# Now run the models\n",
    "\n",
    "best_model_rus = build_models(X_rus, X_test, y_rus, y_test)\n",
    "\n",
    "# So the best model with undersamping and chi test was XGBOOST at 0.7535767458218308 average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do oversampling and feature selection based on variance\n",
    "\n",
    "def feature_selection_variance(df):\n",
    "\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    import numpy as np\n",
    "\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    # Select features with variance above 0.1\n",
    "    selector = VarianceThreshold(threshold=0.1)\n",
    "    selector.fit(X)\n",
    "    mask = selector.get_support()\n",
    "    selected_features = X.columns[mask]\n",
    "\n",
    "    return X[selected_features]\n",
    "\n",
    "\n",
    "# Now select features based on variance\n",
    "\n",
    "X_selected_variance = feature_selection_variance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build function for oversampling\n",
    "\n",
    "def over_sample(df):\n",
    "\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_ros, X_test, y_ros, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaczm\\AppData\\Local\\Temp\\ipykernel_28616\\2761753737.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_var_over['target'] = target_variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n",
      "Accuracy: 0.7775\n",
      "AUC: 0.7201103634349584\n",
      "Average Score (Accuracy + AUC) / 2: 0.7488051817174792\n",
      "Recall: 0.4463061690784463\n",
      "Precision: 0.490787269681742\n",
      "F1: 0.46749102512963703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaczm\\.virtualenvs\\Credit_Card_Risk-I-g6zMjZ\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=42)\n",
      "Accuracy: 0.748\n",
      "AUC: 0.7531527709236434\n",
      "Average Score (Accuracy + AUC) / 2: 0.7505763854618217\n",
      "Recall: 0.6085300837776085\n",
      "Precision: 0.444629938786867\n",
      "F1: 0.5138263665594855\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "Accuracy: 0.753\n",
      "AUC: 0.7390488445703313\n",
      "Average Score (Accuracy + AUC) / 2: 0.7460244222851656\n",
      "Recall: 0.5643564356435643\n",
      "Precision: 0.44881889763779526\n",
      "F1: 0.5\n",
      "Best model based on average score (Accuracy + AUC) / 2: LogisticRegression(random_state=42)\n",
      "Best model average score: 0.7505763854618217\n"
     ]
    }
   ],
   "source": [
    "# Now only choose columns from df based on the selected features, balance data and run models\n",
    "\n",
    "df_var_over = df[X_selected_variance.columns]\n",
    "# add target column to the df\n",
    "df_var_over['target'] = target_variable\n",
    "\n",
    "X_ros, X_test, y_ros, y_test = over_sample(df_var_over)\n",
    "\n",
    "# Now run the models\n",
    "\n",
    "best_model_ros = build_models(X_ros, X_test, y_ros, y_test)\n",
    "\n",
    "# SO the best model with oversampling and variance based feature selection was logistic regression at 0.7505763854618217 average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForest, Feature Selection: SelectKBest, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: SelectKBest, Balancing: SMOTE\n",
      "Accuracy: 0.7936666666666666\n",
      "AUC: 0.7503916538606972\n",
      "Average Score (Accuracy + AUC) / 2: 0.772029160263682\n",
      "Recall: 0.5041888804265042\n",
      "Precision: 0.5300240192153723\n",
      "F1: 0.516783762685402\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 4.008106231689453 seconds ---\n",
      "New best model found!:  RandomForest 0.772029160263682\n",
      "Fitting model: RandomForest, Feature Selection: SelectKBest, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: SelectKBest, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.755\n",
      "AUC: 0.7487904269575503\n",
      "Average Score (Accuracy + AUC) / 2: 0.7518952134787751\n",
      "Recall: 0.6009139375476009\n",
      "Precision: 0.4547550432276657\n",
      "F1: 0.5177165354330708\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 0.8095741271972656 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: SelectKBest, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: SelectKBest, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7606666666666667\n",
      "AUC: 0.7396838754955897\n",
      "Average Score (Accuracy + AUC) / 2: 0.7501752710811282\n",
      "Recall: 0.597105864432597\n",
      "Precision: 0.4636309875813128\n",
      "F1: 0.521970705725699\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 2.2496578693389893 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: VarianceThreshold, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: VarianceThreshold, Balancing: SMOTE\n",
      "Accuracy: 0.7571666666666667\n",
      "AUC: 0.692359040765313\n",
      "Average Score (Accuracy + AUC) / 2: 0.7247628537159898\n",
      "Recall: 0.5422696115765423\n",
      "Precision: 0.45408163265306123\n",
      "F1: 0.4942728219368275\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 0.9002149105072021 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: VarianceThreshold, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: VarianceThreshold, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7571666666666667\n",
      "AUC: 0.6914719799104034\n",
      "Average Score (Accuracy + AUC) / 2: 0.724319323288535\n",
      "Recall: 0.5422696115765423\n",
      "Precision: 0.45408163265306123\n",
      "F1: 0.4942728219368275\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 0.42397403717041016 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: VarianceThreshold, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: VarianceThreshold, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7571666666666667\n",
      "AUC: 0.6914719799104034\n",
      "Average Score (Accuracy + AUC) / 2: 0.724319323288535\n",
      "Recall: 0.5422696115765423\n",
      "Precision: 0.45408163265306123\n",
      "F1: 0.4942728219368275\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 0.8022148609161377 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: RFE, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: RandomForest, Feature Selection: RFE, Balancing: SMOTE\n",
      "Accuracy: 0.7885\n",
      "AUC: 0.7616347723955241\n",
      "Average Score (Accuracy + AUC) / 2: 0.775067386197762\n",
      "Recall: 0.5224676313785225\n",
      "Precision: 0.516566265060241\n",
      "F1: 0.5195001893222264\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 11.27661681175232 seconds ---\n",
      "New best model found!:  RandomForest 0.775067386197762\n",
      "Fitting model: RandomForest, Feature Selection: RFE, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: RandomForest, Feature Selection: RFE, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7335\n",
      "AUC: 0.7662942386868055\n",
      "Average Score (Accuracy + AUC) / 2: 0.7498971193434028\n",
      "Recall: 0.645087585681645\n",
      "Precision: 0.42777777777777776\n",
      "F1: 0.514424536896447\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 2.7843098640441895 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: RFE, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: RandomForest, Feature Selection: RFE, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7925\n",
      "AUC: 0.7638298377112498\n",
      "Average Score (Accuracy + AUC) / 2: 0.7781649188556249\n",
      "Recall: 0.5376999238385377\n",
      "Precision: 0.5252976190476191\n",
      "F1: 0.5314264207753105\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 8.665193319320679 seconds ---\n",
      "New best model found!:  RandomForest 0.7781649188556249\n",
      "Fitting model: RandomForest, Feature Selection: SelectFromModel, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: SelectFromModel, Balancing: SMOTE\n",
      "Accuracy: 0.7846666666666666\n",
      "AUC: 0.7645084173284145\n",
      "Average Score (Accuracy + AUC) / 2: 0.7745875419975405\n",
      "Recall: 0.5064737242955065\n",
      "Precision: 0.5080213903743316\n",
      "F1: 0.5072463768115942\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 29.255061626434326 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: SelectFromModel, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: SelectFromModel, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.734\n",
      "AUC: 0.7731792381286346\n",
      "Average Score (Accuracy + AUC) / 2: 0.7535896190643173\n",
      "Recall: 0.6488956587966489\n",
      "Precision: 0.4287871162556618\n",
      "F1: 0.5163636363636364\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 7.039562940597534 seconds ---\n",
      "Fitting model: RandomForest, Feature Selection: SelectFromModel, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: RandomForest, Feature Selection: SelectFromModel, Balancing: RandomOverSampler\n",
      "Accuracy: 0.796\n",
      "AUC: 0.7698845683422785\n",
      "Average Score (Accuracy + AUC) / 2: 0.7829422841711393\n",
      "Recall: 0.5156130997715156\n",
      "Precision: 0.5351778656126482\n",
      "F1: 0.5252133436772692\n",
      "Best Params: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "--- 22.902619123458862 seconds ---\n",
      "New best model found!:  RandomForest 0.7829422841711393\n",
      "Fitting model: LogisticRegression, Feature Selection: SelectKBest, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: SelectKBest, Balancing: SMOTE\n",
      "Accuracy: 0.7545\n",
      "AUC: 0.7466380978581356\n",
      "Average Score (Accuracy + AUC) / 2: 0.7505690489290677\n",
      "Recall: 0.6054836252856055\n",
      "Precision: 0.4542857142857143\n",
      "F1: 0.5190989226248776\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l2'}\n",
      "--- 0.3931615352630615 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: SelectKBest, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: SelectKBest, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7545\n",
      "AUC: 0.7404064912900179\n",
      "Average Score (Accuracy + AUC) / 2: 0.7474532456450089\n",
      "Recall: 0.6039603960396039\n",
      "Precision: 0.45418098510882016\n",
      "F1: 0.5184700882641387\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 0.2372124195098877 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: SelectKBest, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: SelectKBest, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7586666666666667\n",
      "AUC: 0.7389738530728882\n",
      "Average Score (Accuracy + AUC) / 2: 0.7488202598697775\n",
      "Recall: 0.6031987814166032\n",
      "Precision: 0.4607329842931937\n",
      "F1: 0.5224274406332454\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 0.31535983085632324 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: VarianceThreshold, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: VarianceThreshold, Balancing: SMOTE\n",
      "Accuracy: 0.5931666666666666\n",
      "AUC: 0.5783753770496118\n",
      "Average Score (Accuracy + AUC) / 2: 0.5857710218581392\n",
      "Recall: 0.6641279512566641\n",
      "Precision: 0.30362116991643456\n",
      "F1: 0.416726403823178\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 0.349442720413208 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: VarianceThreshold, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: VarianceThreshold, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.5931666666666666\n",
      "AUC: 0.5783753770496118\n",
      "Average Score (Accuracy + AUC) / 2: 0.5857710218581392\n",
      "Recall: 0.6641279512566641\n",
      "Precision: 0.30362116991643456\n",
      "F1: 0.416726403823178\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 0.20521044731140137 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: VarianceThreshold, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: VarianceThreshold, Balancing: RandomOverSampler\n",
      "Accuracy: 0.5931666666666666\n",
      "AUC: 0.5783753770496118\n",
      "Average Score (Accuracy + AUC) / 2: 0.5857710218581392\n",
      "Recall: 0.6641279512566641\n",
      "Precision: 0.30362116991643456\n",
      "F1: 0.416726403823178\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 0.2301771640777588 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: RFE, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: LogisticRegression, Feature Selection: RFE, Balancing: SMOTE\n",
      "Accuracy: 0.7603333333333333\n",
      "AUC: 0.7557244999253334\n",
      "Average Score (Accuracy + AUC) / 2: 0.7580289166293334\n",
      "Recall: 0.6100533130236101\n",
      "Precision: 0.4638100752750434\n",
      "F1: 0.5269736842105263\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 2.579789400100708 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: RFE, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: LogisticRegression, Feature Selection: RFE, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7406666666666667\n",
      "AUC: 0.756900477101919\n",
      "Average Score (Accuracy + AUC) / 2: 0.7487835718842928\n",
      "Recall: 0.6306169078446306\n",
      "Precision: 0.43601895734597157\n",
      "F1: 0.5155666251556662\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 0.7398004531860352 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: RFE, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: LogisticRegression, Feature Selection: RFE, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7598333333333334\n",
      "AUC: 0.7539414409839663\n",
      "Average Score (Accuracy + AUC) / 2: 0.7568873871586499\n",
      "Recall: 0.5887281035795887\n",
      "Precision: 0.46176821983273597\n",
      "F1: 0.5175761633746234\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 2.217376708984375 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: SelectFromModel, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: SelectFromModel, Balancing: SMOTE\n",
      "Accuracy: 0.758\n",
      "AUC: 0.7576597355456935\n",
      "Average Score (Accuracy + AUC) / 2: 0.7578298677728468\n",
      "Recall: 0.6115765422696116\n",
      "Precision: 0.46017191977077365\n",
      "F1: 0.5251798561151079\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 17.424055337905884 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: SelectFromModel, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: SelectFromModel, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7611666666666667\n",
      "AUC: 0.7555406366981252\n",
      "Average Score (Accuracy + AUC) / 2: 0.7583536516823959\n",
      "Recall: 0.5993907083015994\n",
      "Precision: 0.46458087367178275\n",
      "F1: 0.523445294313269\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "--- 4.084029912948608 seconds ---\n",
      "Fitting model: LogisticRegression, Feature Selection: SelectFromModel, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model: LogisticRegression, Feature Selection: SelectFromModel, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7668333333333334\n",
      "AUC: 0.7540005079597422\n",
      "Average Score (Accuracy + AUC) / 2: 0.7604169206465378\n",
      "Recall: 0.5993907083015994\n",
      "Precision: 0.47409638554216865\n",
      "F1: 0.5294315506222671\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l2'}\n",
      "--- 12.40891695022583 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: SelectKBest, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: SelectKBest, Balancing: SMOTE\n",
      "Accuracy: 0.796\n",
      "AUC: 0.7219732074797803\n",
      "Average Score (Accuracy + AUC) / 2: 0.7589866037398902\n",
      "Recall: 0.4211728865194212\n",
      "Precision: 0.543756145526057\n",
      "F1: 0.47467811158798284\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 1.6396753787994385 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: SelectKBest, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: SelectKBest, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7503333333333333\n",
      "AUC: 0.7336033081406317\n",
      "Average Score (Accuracy + AUC) / 2: 0.7419683207369825\n",
      "Recall: 0.5902513328255903\n",
      "Precision: 0.44668587896253603\n",
      "F1: 0.5085301837270341\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 0.7185559272766113 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: SelectKBest, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: SelectKBest, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7621666666666667\n",
      "AUC: 0.7202562840518678\n",
      "Average Score (Accuracy + AUC) / 2: 0.7412114753592672\n",
      "Recall: 0.5651180502665651\n",
      "Precision: 0.4643304130162703\n",
      "F1: 0.5097904500171763\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 1.3422987461090088 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: VarianceThreshold, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: VarianceThreshold, Balancing: SMOTE\n",
      "Accuracy: 0.7571666666666667\n",
      "AUC: 0.692359040765313\n",
      "Average Score (Accuracy + AUC) / 2: 0.7247628537159898\n",
      "Recall: 0.5422696115765423\n",
      "Precision: 0.45408163265306123\n",
      "F1: 0.4942728219368275\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 0.5499484539031982 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: VarianceThreshold, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: VarianceThreshold, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7571666666666667\n",
      "AUC: 0.6914719799104034\n",
      "Average Score (Accuracy + AUC) / 2: 0.724319323288535\n",
      "Recall: 0.5422696115765423\n",
      "Precision: 0.45408163265306123\n",
      "F1: 0.4942728219368275\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 0.3252992630004883 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: VarianceThreshold, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: VarianceThreshold, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7571666666666667\n",
      "AUC: 0.6914719799104034\n",
      "Average Score (Accuracy + AUC) / 2: 0.724319323288535\n",
      "Recall: 0.5422696115765423\n",
      "Precision: 0.45408163265306123\n",
      "F1: 0.4942728219368275\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 0.4136507511138916 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: RFE, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: XGBoost, Feature Selection: RFE, Balancing: SMOTE\n",
      "Accuracy: 0.7815\n",
      "AUC: 0.7406187099155009\n",
      "Average Score (Accuracy + AUC) / 2: 0.7610593549577505\n",
      "Recall: 0.4584920030464585\n",
      "Precision: 0.5008319467554077\n",
      "F1: 0.478727634194831\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 5.433157444000244 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: RFE, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: XGBoost, Feature Selection: RFE, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7021666666666667\n",
      "AUC: 0.7431542837532018\n",
      "Average Score (Accuracy + AUC) / 2: 0.7226604752099343\n",
      "Recall: 0.6496572734196496\n",
      "Precision: 0.3912844036697248\n",
      "F1: 0.4884053821929573\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 2.102940320968628 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: RFE, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Model: XGBoost, Feature Selection: RFE, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7868333333333334\n",
      "AUC: 0.7460814708278201\n",
      "Average Score (Accuracy + AUC) / 2: 0.7664574020805768\n",
      "Recall: 0.4706778370144707\n",
      "Precision: 0.5141430948419301\n",
      "F1: 0.4914512922465209\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 4.540099620819092 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: SelectFromModel, Balancing: SMOTE\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: SelectFromModel, Balancing: SMOTE\n",
      "Accuracy: 0.7941666666666667\n",
      "AUC: 0.746439853812891\n",
      "Average Score (Accuracy + AUC) / 2: 0.7703032602397788\n",
      "Recall: 0.43488194973343486\n",
      "Precision: 0.5366541353383458\n",
      "F1: 0.48043752629364744\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 20.390056371688843 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: SelectFromModel, Balancing: RandomUnderSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: SelectFromModel, Balancing: RandomUnderSampler\n",
      "Accuracy: 0.7113333333333334\n",
      "AUC: 0.7563834176330929\n",
      "Average Score (Accuracy + AUC) / 2: 0.7338583754832131\n",
      "Recall: 0.6428027418126429\n",
      "Precision: 0.40056953013763646\n",
      "F1: 0.4935672514619883\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 6.232625961303711 seconds ---\n",
      "Fitting model: XGBoost, Feature Selection: SelectFromModel, Balancing: RandomOverSampler\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Model: XGBoost, Feature Selection: SelectFromModel, Balancing: RandomOverSampler\n",
      "Accuracy: 0.7988333333333333\n",
      "AUC: 0.7605432114332865\n",
      "Average Score (Accuracy + AUC) / 2: 0.7796882723833098\n",
      "Recall: 0.43716679360243715\n",
      "Precision: 0.5508637236084453\n",
      "F1: 0.48747346072186837\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "--- 16.49241065979004 seconds ---\n",
      "Best model based on average score (Accuracy + AUC) / 2: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('balancer', RandomOverSampler(random_state=42)),\n",
      "                ('feature_selector',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42))),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=20, min_samples_leaf=4,\n",
      "                                        min_samples_split=5,\n",
      "                                        random_state=42))])\n",
      "Best model average score: 0.7829422841711393\n",
      "Best model parameters: {'model__max_depth': 20, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Class selection has so far not improved the model \n",
    "# I will also test a self made grid search function to find the best model\n",
    "\n",
    "def grid_search(df):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, RFE, SelectFromModel\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    import time\n",
    "\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = [\n",
    "        ('RandomForest', RandomForestClassifier(random_state=42), {\n",
    "            'model__n_estimators': [100],\n",
    "            'model__max_depth': [20],\n",
    "            'model__min_samples_split': [5],\n",
    "            'model__min_samples_leaf': [4]\n",
    "        }),\n",
    "        ('LogisticRegression', LogisticRegression(random_state=42, solver='liblinear'), {\n",
    "            'model__C': [10],\n",
    "            'model__penalty': ['l1', 'l2']\n",
    "        }),\n",
    "        ('XGBoost', xgb.XGBClassifier(random_state=42), {\n",
    "            'model__n_estimators': [100],\n",
    "            'model__max_depth': [20],\n",
    "            'model__learning_rate': [0.1]\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    feature_selection_methods = [\n",
    "        ('SelectKBest', SelectKBest(score_func=chi2, k=10)),\n",
    "        ('VarianceThreshold', VarianceThreshold(threshold=0.1)),\n",
    "        ('RFE', RFE(LogisticRegression(random_state=42), n_features_to_select=10, step=1, verbose=1)),\n",
    "        ('SelectFromModel', SelectFromModel(RandomForestClassifier(random_state=42)))\n",
    "    ]\n",
    "\n",
    "    balancing_methods = [\n",
    "        ('SMOTE', SMOTE(random_state=42)),\n",
    "        ('RandomUnderSampler', RandomUnderSampler(random_state=42)),\n",
    "        ('RandomOverSampler', RandomOverSampler(random_state=42))\n",
    "    ]\n",
    "\n",
    "    best_model_score = 0\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    for model_name, model, param_grid in models:\n",
    "        for fs_name, feature_selection_method in feature_selection_methods:\n",
    "            for bm_name, balancing_method in balancing_methods:\n",
    "                print(f'Fitting model: {model_name}, Feature Selection: {fs_name}, Balancing: {bm_name}')\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Create a pipeline\n",
    "                pipeline = ImbPipeline([\n",
    "                    ('scaler', MinMaxScaler()),\n",
    "                    ('balancer', balancing_method),\n",
    "                    ('feature_selector', feature_selection_method),\n",
    "                    ('model', model)\n",
    "                ])\n",
    "\n",
    "                # Combine the parameter grid with model parameters\n",
    "                grid = GridSearchCV(pipeline, param_grid, scoring='roc_auc', refit=True, cv=3, verbose=3, n_jobs=-1)\n",
    "                try:\n",
    "                    grid.fit(X_train, y_train)\n",
    "\n",
    "                    y_pred = grid.predict(X_test)\n",
    "                    y_proba = grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    auc = roc_auc_score(y_test, y_proba)\n",
    "                    average_score = (accuracy + auc) / 2\n",
    "\n",
    "                    print(f\"Model: {model_name}, Feature Selection: {fs_name}, Balancing: {bm_name}\")\n",
    "                    print('Accuracy:', accuracy)\n",
    "                    print('AUC:', auc)\n",
    "                    print('Average Score (Accuracy + AUC) / 2:', average_score)\n",
    "                    print('Recall:', recall_score(y_test, y_pred))\n",
    "                    print('Precision:', precision_score(y_test, y_pred))\n",
    "                    print('F1:', f1_score(y_test, y_pred))\n",
    "                    print('Best Params:', grid.best_params_)\n",
    "                    print(f\"--- {time.time() - start_time} seconds ---\")\n",
    "\n",
    "                    if average_score > best_model_score:\n",
    "                        print('New best model found!: ', model_name, average_score)\n",
    "                        best_model_score = average_score\n",
    "                        best_model = grid.best_estimator_\n",
    "                        best_params = grid.best_params_\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to fit model: {model_name}, Feature Selection: {fs_name}, Balancing: {bm_name}\")\n",
    "                    print(str(e))\n",
    "\n",
    "    print('Best model based on average score (Accuracy + AUC) / 2:', best_model)\n",
    "    print('Best model average score:', best_model_score)\n",
    "    print('Best model parameters:', best_params)\n",
    "    return best_model\n",
    "\n",
    "# Example usage:\n",
    "best_model = grid_search(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;balancer&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42))),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=4,\n",
       "                                        min_samples_split=5,\n",
       "                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;balancer&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42))),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=4,\n",
       "                                        min_samples_split=5,\n",
       "                                        random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">RandomOverSampler</label><div class=\"sk-toggleable__content fitted\"><pre>RandomOverSampler(random_state=42)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;feature_selector: SelectFromModel<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.SelectFromModel.html\">?<span>Documentation for feature_selector: SelectFromModel</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SelectFromModel(estimator=RandomForestClassifier(random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
       "                       random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('balancer', RandomOverSampler(random_state=42)),\n",
       "                ('feature_selector',\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42))),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=4,\n",
       "                                        min_samples_split=5,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/kaczm/Desktop/Credit Card Risk/best_model.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_model, 'C:/Users/kaczm/Desktop/Credit Card Risk/best_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Credit_Card_Risk-I-g6zMjZ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
